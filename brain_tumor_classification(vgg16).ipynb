{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "brain tumor classification(vgg16 수정).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a958a992bc63432d99cb4776072673df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ed37e82cc118466a9cab3fce0a3c74be",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_59f5d3a3ed2146b2a238d42973d8878c",
              "IPY_MODEL_7d01ccdf3fd84366af1684d8a98c6a8a"
            ]
          }
        },
        "ed37e82cc118466a9cab3fce0a3c74be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "59f5d3a3ed2146b2a238d42973d8878c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_04a2859e772841aa8a2047d5eb4f9ed8",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553507836,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553507836,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_628bcf7abf9044e6ba27bcfc962bf70b"
          }
        },
        "7d01ccdf3fd84366af1684d8a98c6a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_59d87e38d428478d854685140a0130bb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [00:02&lt;00:00, 241MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_62d7ce141a2c4e8498b973aa15c66cc6"
          }
        },
        "04a2859e772841aa8a2047d5eb4f9ed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "628bcf7abf9044e6ba27bcfc962bf70b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "59d87e38d428478d854685140a0130bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "62d7ce141a2c4e8498b973aa15c66cc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yaeeun916/RP-Lab-DL-School-HW/blob/main/brain_tumor_classification(vgg16).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkkXubDF2Uuu"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from skimage import io, transform\n",
        "import torchvision\n",
        "from torchvision import models, transforms, utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt \n",
        "import zipfile\n",
        "import time\n",
        "import os\n",
        "\n",
        "# 경고 메시지 무시하기\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# 반응형 모드 설정 (바로 그래프가 업데이트 된다)\n",
        "plt.ion() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YZd9Du7cfQt",
        "outputId": "379d3bc0-6943-41ff-93b3-796a13b0dd92"
      },
      "source": [
        "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 재생산성(재실행해도 같은 결과가 나오도록)을 위해 랜덤 시드를 준다\n",
        "torch.manual_seed(777)\n",
        "if device=='cuda':\n",
        "  torch.cuda.manual_seed_all(777)\n",
        "\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rykNzW_5qz4"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "https://tutorials.pytorch.kr/recipes/recipes/custom_dataset_transforms_loader.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQYsQ4RN5yak"
      },
      "source": [
        "## 데이터 다운받아 ./data/brain_tumor/ 경로에 위치시키기\n",
        "\n",
        "참고: 다운받은 뇌종양 데이터셋의 구조\n",
        "\n",
        "Brain-Tumor-Classification-DataSet-master 폴더 내에 Testing, Training 폴더 내에 glioma_tumor, meningioma_tumor, no_tumor, pituitary_tumor 폴더\n",
        "\n",
        "glioma_tumor, meningioma_tumor, no_tumor, pituitary_tumor 폴더 내에 이미지 (파일 이름: image(인덱스).jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBDo_5lR27C5",
        "outputId": "b0910cdc-08a9-48dc-f912-12c0f06d57b1"
      },
      "source": [
        "!wget https://github.com/SartajBhuvaji/Brain-Tumor-Classification-DataSet/archive/master.zip\n",
        "os.makedirs(\"./data/brain_tumor/\", exist_ok=True) #exist_ok=True: 해당 디렉토리가 기존에 존재하면 넘어가고, 없을 경우에만 생성\n",
        "if not os.path.exists(\"./data/brain_tumor/master.zip\"): #동일 경로에 다운받은적 없다면\n",
        "  with zipfile.ZipFile(\"master.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"./data/brain_tumor/\") #./data/brain_tumor/에 압축 해제"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-03 05:03:49--  https://github.com/SartajBhuvaji/Brain-Tumor-Classification-DataSet/archive/master.zip\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/SartajBhuvaji/Brain-Tumor-Classification-DataSet/zip/master [following]\n",
            "--2021-03-03 05:03:50--  https://codeload.github.com/SartajBhuvaji/Brain-Tumor-Classification-DataSet/zip/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.121.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.121.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [               <=>  ]  86.97M  26.4MB/s    in 3.5s    \n",
            "\n",
            "2021-03-03 05:03:53 (24.7 MB/s) - ‘master.zip’ saved [91198591]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4oXldDM53cu"
      },
      "source": [
        "## class로 custom dataset 만들기\n",
        "기본 구성:\n",
        "\n",
        "def init(self, x, transform)\n",
        "\n",
        "def len(self)\n",
        "\n",
        "def getitem(self,index)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jno98kIW27oN"
      },
      "source": [
        "class BrainTumorDataset(Dataset): #class Dataset을 상속한 class BrainTumorDataset\n",
        "  train_list=[\"Brain-Tumor-Classification-DataSet-master/Training/no_tumor\",\n",
        "              \"Brain-Tumor-Classification-DataSet-master/Training/glioma_tumor\",\n",
        "              \"Brain-Tumor-Classification-DataSet-master/Training/meningioma_tumor\",\n",
        "              \"Brain-Tumor-Classification-DataSet-master/Training/pituitary_tumor\"]\n",
        "  test_list=[\"Brain-Tumor-Classification-DataSet-master/Testing/no_tumor\",\n",
        "             \"Brain-Tumor-Classification-DataSet-master/Testing/glioma_tumor\",\n",
        "              \"Brain-Tumor-Classification-DataSet-master/Testing/meningioma_tumor\",\n",
        "              \"Brain-Tumor-Classification-DataSet-master/Testing/pituitary_tumor\"]\n",
        "\n",
        "  def __init__(self, root_dir=\"./data/brain_tumor/\", train=True, transform=None):\n",
        "      #매개변수 :\n",
        "      #    root_dir (문자열): 모든 이미지가 있는 폴더 경로 \n",
        "      #    train: True면 train set, False면 test set\n",
        "      #    transform (호출가능한 함수, 선택적 매개변수): 샘플에 적용 될 수 있는 선택적 변환\n",
        "      #    __init__에선 이미지를 읽지 않고 __getitem__에서 읽는다 (메모리)\n",
        "      self.root_dir = root_dir\n",
        "      self.train = train  \n",
        "      self.transform = transform\n",
        "\n",
        "      if self.train:\n",
        "        self.train_data=[] # 이미지 파일의 경로를 append할 list\n",
        "        self.train_label=[] # label(0~3)을 append할 list\n",
        "        for tr in BrainTumorDataset.train_list: \n",
        "          folder=os.path.join(self.root_dir, tr) #glioma_tumor, meningioma_tumor, no_tumor, pituitary_tumor 폴더의 경로\n",
        "          for currentdir, dirs, files in os.walk(folder): \n",
        "            for file in files: #files: folder 내 모든 파일\n",
        "              image_name=os.path.join(folder, file) #image_name=이미지 파일의 경로\n",
        "              self.train_data.append(image_name)\n",
        "              self.train_label.append(BrainTumorDataset.train_list.index(tr)) \n",
        "              # torch.nn.CrossEntropyLoss expects a class index (0 to C-1) as the target \n",
        "              #  :no_tumor는 0, glioma_tumor는 1, meningioma_tumor는 2, pituitary_tumor는 3으로 train_label에 append\n",
        "              # one hot encoding은 torch.nn.CrossEntropyLoss가 해줌\n",
        "      else:\n",
        "        self.test_data=[]\n",
        "        self.test_label=[]\n",
        "        for ts in BrainTumorDataset.test_list:\n",
        "          folder=os.path.join(self.root_dir, ts)\n",
        "          for currentdir, dirs, files in os.walk(folder):\n",
        "            for file in files:\n",
        "              image_name=os.path.join(folder, file)\n",
        "              self.test_data.append(image_name)\n",
        "              self.test_label.append(BrainTumorDataset.test_list.index(ts))\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "      if self.train:\n",
        "        return len(self.train_data)\n",
        "      else:\n",
        "        return len(self.test_data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "      \n",
        "      if self.train:\n",
        "        img, target=io.imread(self.train_data[idx]), self.train_label[idx]\n",
        "      else:\n",
        "        img, target=io.imread(self.test_data[idx]), self.test_label[idx]\n",
        "      # skimage : represent image as numpy array, provides easy-to-use functions for reading, displaying, and saving images\n",
        "      # skimage.io.imread : reads the image, converts it from JPEG into a NumPy array, and returns the array (numpy image: H x W x C)\n",
        "\n",
        "      if self.transform:\n",
        "        img=self.transform(img)\n",
        "\n",
        "      return img, target\n",
        "      # img는 numpy array, target은 int"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhLFsbBeWl1n"
      },
      "source": [
        "## 데이터 전처리\n",
        "위에서 볼 수 있었던 한가지 문제점은 샘플들이 다 같은 사이즈가 아니라는 것. 대부분의 신경망(neural networks)은 고정된 크기의 이미지라고 가정하므로 신경망에 주기 전에 처리할 과정을 작성해야 한다.\n",
        "All transformations accept PIL Image, Tensor Image\n",
        "\n",
        "*   transforms.ToPILImage(): Convert a tensor or an ndarray to PIL Image. 만든 데이터셋은 numpy array를 append하는데 transformation은 PIL 또는 tensor를 받기 때문에. ToTensor()먼저 안 하는 이유는 range가 [0.0, 1.0]으로 바껴서\n",
        "*   transforms.Resize(size): 이미지 크기 변경, image can be a PIL Image or a torch Tensor \n",
        "*   transforms.ColorJitter(): Randomly change the brightness, contrast and saturation of an image. data augmentation 중 제일 뇌 영상에 적합하다고 생각해서 선정. 방향이 정확히 맞춰서 들어온다고 가정할 수 있으니 굳이 플립, 로테이션은 하지 않기로.\n",
        "*   transforms.ToTensor(): Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n",
        "PyTorch는 tensor를 사용하므로 numpy 이미지들을 Torch.tensor 이미지로 변환\n",
        "*    transforms.Normalize(mean, std): normalize\n",
        "\n",
        "모든 pretrained model을 쓸 때 이미지 데이터는 [3, H, W] 형식이어야 하고, H,W는 224 이상이어야 한다. 또 아래 코드처럼 정규화된 이미지 데이터로 학습된 것이기 때문에, 이 모델들을 사용할 때에는 데이터셋을 이와 같이 정규화시켜주어야 한다.\n",
        "\n",
        "transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                     std=[0.229, 0.224, 0.225])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBwGWJL8Fz0a"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "                                transforms.ToPILImage(),\n",
        "                                transforms.Resize((224, 224)),\n",
        "                                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                ]) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1Tfo7S0n75z"
      },
      "source": [
        "trainset=BrainTumorDataset(root_dir='./data/brain_tumor/',\n",
        "                              train=True,\n",
        "                              transform=transform)\n",
        "\n",
        "#split train set into train set & validation set\n",
        "train_size = int(0.8 * len(trainset))\n",
        "val_size = len(trainset) - train_size\n",
        "trainset, valset = torch.utils.data.random_split(trainset, [train_size, val_size], generator=torch.Generator().manual_seed(777))\n",
        "\n",
        "testset=brain_train=BrainTumorDataset(root_dir='./data/brain_tumor/',\n",
        "                              train=False,\n",
        "                              transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxew4mZU6EJ7"
      },
      "source": [
        "# Dataloader \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPMp9avBW1Ky"
      },
      "source": [
        "batchsize = 30\n",
        "\n",
        "trainloader = DataLoader(dataset=trainset, \n",
        "                        batch_size=batchsize,\n",
        "                        shuffle=True,\n",
        "                        drop_last=True)\n",
        "\n",
        "valloader = DataLoader(dataset=valset, \n",
        "                        batch_size=batchsize,\n",
        "                        shuffle=True,\n",
        "                        drop_last=True)\n",
        "\n",
        "testloader = DataLoader(dataset=testset, \n",
        "                         batch_size=1, \n",
        "                         shuffle=False, #test는 셔플할 필요 없음\n",
        "                         drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGWFO6Os6luj"
      },
      "source": [
        "# 모델 만들기\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm4NuGXdV3An"
      },
      "source": [
        "## pretrained VGG16\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv2yKW995PDR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a958a992bc63432d99cb4776072673df",
            "ed37e82cc118466a9cab3fce0a3c74be",
            "59f5d3a3ed2146b2a238d42973d8878c",
            "7d01ccdf3fd84366af1684d8a98c6a8a",
            "04a2859e772841aa8a2047d5eb4f9ed8",
            "628bcf7abf9044e6ba27bcfc962bf70b",
            "59d87e38d428478d854685140a0130bb",
            "62d7ce141a2c4e8498b973aa15c66cc6"
          ]
        },
        "outputId": "c9cb2344-83fc-4438-911a-db5e189b02fc"
      },
      "source": [
        "net = models.vgg16_bn(pretrained=True)#vgg16 with batch normalization\n",
        "for param in net.parameters():\n",
        "    param.requires_grad = True        #fine-tune entire network\n",
        "net.classifier[6].out_features = 4    #net의 마지막 레이어 교체 (brain tumor classification의 class 수는 4)\n",
        "net.to(device)\n",
        "\n",
        "#구조 확인\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a958a992bc63432d99cb4776072673df",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553507836.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fBIQwlg6s93"
      },
      "source": [
        "# 학습\n",
        "\n",
        "https://www.kaggle.com/carloalbertobarbano/vgg16-transfer-learning-pytorch\n",
        "\n",
        "https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CauqBz7l6y4f"
      },
      "source": [
        "## 학습시키기\n",
        "\n",
        "transfer learning\n",
        "- 학습할 dataset이 original dataset과 very similar/very different한지, very little data/quite a lot of data인지에 따라 layer를 얼만큼 freeze하고 얼만큼 train할지 결정\n",
        "- brain tumor dataset은 different from original dataset(ImageNet) & large : fine-tune entire network\n",
        "- lr: 1/10of original lr에서 시작\n",
        "\n",
        "https://tutorials.pytorch.kr/beginner/transfer_learning_tutorial.html\n",
        "https://www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/lr_scheduling/\n",
        "\n",
        "\n",
        "스케줄러마다 적용시 사용 방식이 다름:\n",
        "http://www.gisdeveloper.co.kr/?p=8443"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGKsqGpysizy"
      },
      "source": [
        "def train_model(model, criterion, optimizer, lr_sche, num_epochs, PATH):\n",
        "  since = time.time()\n",
        "\n",
        "  #best accuracy\n",
        "  best_acc = 0.0 \n",
        "\n",
        "  train_cost_list=[]\n",
        "  train_acc_list=[]\n",
        "  val_cost_list=[]\n",
        "  val_acc_list=[]\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "      print('-' * 10)\n",
        "\n",
        "      #train phase\n",
        "      lr_sche.step() # 만약 lr_scheduler.ReduceLROnPlateau쓸거면 optimizer.step() 다음에 와야함(링크 참고)\n",
        "      model.train()  # Set model to training mode\n",
        "              \n",
        "      cost_train = 0.0  \n",
        "      corrects_train = 0 \n",
        "\n",
        "      for X, Y in trainloader: #for each batch\n",
        "          X=X.float().to(device)\n",
        "          Y=Y.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          hypothesis=model(X)\n",
        "          preds=torch.argmax(hypothesis, 1)\n",
        "          cost=criterion(hypothesis, Y)\n",
        "\n",
        "          # backward + optimize only if in training phase (validation set으로는 학습하지 않는다)\n",
        "          cost.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          cost_train += cost.item() # 한 epoch 내 모든 batch의 cost 누적(+=cost하면 history도 저장됨. +=cost.item()해야 numerical data만 저장)\n",
        "          corrects_train += torch.sum(preds == Y).item() # 한 epoch 내 모든 batch의 맞춘 갯수 누적\n",
        "\n",
        "      epoch_cost = cost_train / len(trainloader)\n",
        "      epoch_acc = corrects_train / (X.size(0)*len(trainloader))\n",
        "        # drop_last=True로 했기 때문에 이렇게 계산\n",
        "        #     : 항상 batch의 데이터 수(=X.size(0)) = 설정한 batch size\n",
        "        #     : 1 epoch에서 사용된 데이터 수 = X.size(0)*total_batch != len(trainset). trainset의 모든 데이터 사용X\n",
        "\n",
        "        # drop_last=False라면 trainset의 모든 데이터가 사용되고, 마지막 batch의 데이터 수는 설정한 batch size보다 작음\n",
        "        #     : cost_train += cost * X.size(0)           => cost는 1batch내 모든 데이터의 cost의 평균이니 다시 X.size(0) 곱해주고\n",
        "        #     : epoch_cost = cost_train / len(trainset)  => 사용된 데이터 수로 나눠줌\n",
        "\n",
        "      print('Train Cost: {:.4f} Acc: {:.4f}'.format(epoch_cost, epoch_acc))\n",
        "      train_cost_list.append(epoch_cost)\n",
        "      train_acc_list.append(epoch_acc)\n",
        "\n",
        "\n",
        "      #validation phase : 5 epoch마다\n",
        "      if epoch%5==4:\n",
        "        with torch.no_grad():# 학습 안 할 것이니 computation 저장X, frees GPU spaces\n",
        "          model.eval()  # Set model to evaluate mode : batchnorm은 학습에서 저장된 파라미터 사용,  dropout은 비활성화\n",
        "\n",
        "          cost_val = 0.0\n",
        "          corrects_val = 0\n",
        "\n",
        "          for X, Y in valloader:\n",
        "              X=X.float().to(device)\n",
        "              Y=Y.to(device)\n",
        "\n",
        "              optimizer.zero_grad()\n",
        "              hypothesis=model(X)\n",
        "              preds = torch.argmax(hypothesis, 1)\n",
        "              cost = criterion(hypothesis, Y)\n",
        "\n",
        "              cost_val += cost.item() \n",
        "              corrects_val += torch.sum(preds == Y).item()\n",
        "\n",
        "          epoch_cost_val = cost_val / len(valloader)\n",
        "          epoch_acc_val = corrects_val / (X.size(0)*len(valloader))\n",
        "\n",
        "          print('Validation Cost: {:.4f} Acc: {:.4f}'.format(epoch_cost_val, epoch_acc_val))\n",
        "          val_cost_list.append(epoch_cost_val)\n",
        "          val_acc_list.append(epoch_acc_val)\n",
        "\n",
        "          # validation set에서 accuracy 가장 높았던 hyperparameter를 선택, 저장\n",
        "          if epoch_acc_val > best_acc:\n",
        "            best_acc = epoch_acc_val\n",
        "            torch.save(model.state_dict(), PATH)\n",
        "\n",
        "      print()\n",
        "\n",
        "\n",
        "  time_elapsed = time.time() - since\n",
        "  print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "  print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "\n",
        "  # Loss Tracker, Accuracy Tracker 그래프 그리기\n",
        "  plt.subplot(2,1,1)\n",
        "  plt.plot(train_cost_list, 'r', label='train cost') #plot(y): plot y using x as index array 0..N-1\n",
        "  plt.plot([5*x+4 for x in range(num_epochs//5)], val_cost_list, 'b', label='val cost') #plot(x, y)    \n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('cost')\n",
        "  plt.title('Loss Tracker')\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.show()\n",
        "\n",
        "  plt.subplot(2,2,2)\n",
        "  plt.plot(train_acc_list, 'r', label='train acc')\n",
        "  plt.plot([5*x+4 for x in range(num_epochs//5)], val_acc_list, 'b', label='val acc')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.title('Accuracy Tracker')\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtJ1Di81Y5K1"
      },
      "source": [
        "criterion=nn.CrossEntropyLoss() \n",
        "optimizer=torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "lr_sche=torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
        "#lr_sche=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, threshold=0.0001)\n",
        "num_epochs=5\n",
        "PATH = './braintumor_model.pth'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhZ7PBYdBEWU",
        "outputId": "ca16d134-b9cd-40fc-fccf-5c26761cd98a"
      },
      "source": [
        "train_model(net, criterion, optimizer, lr_sche, num_epochs, PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/4\n",
            "----------\n",
            "Train Cost: 1.1228 Acc: 0.7316\n",
            "\n",
            "Epoch 1/4\n",
            "----------\n",
            "Train Cost: 0.1669 Acc: 0.9417\n",
            "\n",
            "Epoch 2/4\n",
            "----------\n",
            "Train Cost: 0.0703 Acc: 0.9772\n",
            "\n",
            "Epoch 3/4\n",
            "----------\n",
            "Train Cost: 0.0323 Acc: 0.9908\n",
            "\n",
            "Epoch 4/4\n",
            "----------\n",
            "Train Cost: 0.0214 Acc: 0.9934\n",
            "Validation Cost: 0.2002 Acc: 0.9281\n",
            "\n",
            "Training complete in 3m 40s\n",
            "Best val Acc: 0.928070\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVHyG5FD6uAU"
      },
      "source": [
        "# 5. 테스트"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-1BY7S67P0v"
      },
      "source": [
        "## 5.1 저장한 hyperparameter 불러오기\n",
        "- GPU에서 저장하고 GPU에서 불러오기\n",
        "\n",
        "https://tutorials.pytorch.kr/beginner/saving_loading_models.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIwW6tCvT5nI",
        "outputId": "c839428a-110b-4602-b1fd-2b047ae0dc00"
      },
      "source": [
        "net.load_state_dict(torch.load(PATH))\n",
        "net.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): ReLU(inplace=True)\n",
              "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (26): ReLU(inplace=True)\n",
              "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (32): ReLU(inplace=True)\n",
              "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (36): ReLU(inplace=True)\n",
              "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (39): ReLU(inplace=True)\n",
              "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (42): ReLU(inplace=True)\n",
              "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FA0FqeZi7Vff"
      },
      "source": [
        "## 5.2 테스트하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiM00Idy2vHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36ef241b-cbd1-478f-afa5-b5bbe69e9584"
      },
      "source": [
        "with torch.no_grad(): #학습을 진행하지 않을 것이므로 torch.no_grad()\n",
        "    net.eval() #model에 batch normalization 있으면 train mode, eval mode 구별 필요\n",
        "    correct_predictions=0\n",
        "    for X, Y in testloader: #batch_size=1\n",
        "        X=X.float().to(device)\n",
        "        Y=Y.to(device)\n",
        "\n",
        "        prediction=net(X)\n",
        "        correct_prediction=torch.argmax(prediction, 1)==Y #boolean tensor(True, False)\n",
        "        correct_predictions+=correct_prediction.float().item() #boolean tensor에서 float tensor에서 scalar로\n",
        "    accuracy=correct_predictions/len(testloader) #batch size 1로 했으니 len(testset)=len(testloader)\n",
        "    print('Test Acc:', accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Acc: 0.766497461928934\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}